# ğŸ’ Hurricanes News Dashboard

A full pipeline project that collects Carolina Hurricanes news articles, structures the data with LLMs, stores it in Supabase, and visualizes insights in a Streamlit dashboard deployed on Modal.

---

## ğŸš€ Features
- **Web Scraping**: Collects fresh Carolina Hurricanes news articles.
- **Data Structuring**: Uses GPT to normalize scraped content into JSON (title, author, published date, summary, tags, link).
- **Database Storage**: Saves structured data into a Supabase `articles` table with RLS policies for secure access.
- **Visualization**: Streamlit dashboard showing:
  - All articles with metadata
  - Articles per day
  - Top authors by article count
- **Deployment**: Dashboard runs on [Modal](https://modal.com) with automatic builds.

---

## ğŸ› ï¸ Tech Stack
- **Python** (3.11)
- **Supabase** (Postgres, row-level security)
- **OpenAI GPT-4o** (structuring unstructured text)
- **Streamlit** (interactive dashboard)
- **Modal** (serverless deployment)

## Proof of Deployment

### 1) Modal deployment output
![Terminal showing Modal deploy URL](docs/bash_deployment.png)

### 2) Live dashboard (local run)
![Streamlit dashboard](docs/dashboard.png)

### 3) Supabase table populated
![Supabase articles table](docs/supabase_pipeline.png)


---

## ğŸ“‚ Project Structure
canes_news_pipeline/
â”‚â”€â”€ .venv/ # virtual environment
â”‚â”€â”€ data/ # intermediate and structured data
â”‚ â”œâ”€â”€ raw_blob.txt
â”‚ â”œâ”€â”€ structured.json
â”‚â”€â”€ src/ # pipeline scripts
â”‚ â”œâ”€â”€ collect.py # scrape articles
â”‚ â”œâ”€â”€ structure.py # LLM structuring
â”‚ â”œâ”€â”€ load.py # load into Supabase
â”‚â”€â”€ streamlit_app.py # dashboard
â”‚â”€â”€ modal_app.py # deployment entrypoint
â”‚â”€â”€ .env # Supabase keys (gitignored)
â”‚â”€â”€ .gitignore
â”‚â”€â”€ README.md